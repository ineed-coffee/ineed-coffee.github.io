---
title: 【Lecture 7】 Optimization (CSC321 2017 winter)
author: INEED COFFEE
date: 2021-01-30 14:00:00 +0800
categories: [ML/DL,Deep Learning]
tags: [deep learning,csc321,neural network,back optimization]
toc: true
comments: true
typora-root-url: ../
---
# Course Study with [CSC321](https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/) 



### [2021.01.30]

__`Topic`__  **:** **Lecture 7: Optimization** 

__`Notes`__ : [https://drive.google.com/file/d/1gq4tCKfcwQ_QYRO8XYhdR3Y3UTfJQXNd/view?usp=sharing](https://drive.google.com/file/d/1gq4tCKfcwQ_QYRO8XYhdR3Y3UTfJQXNd/view?usp=sharing) 

__`Links`__ : 

- [Derivative of Logistic Regression](https://medium.com/analytics-vidhya/derivative-of-log-loss-function-for-logistic-regression-9b832f025c2d)
- [what is convex function?](https://ratsgo.github.io/convex%20optimization/2017/12/26/convexfunction/)
- [cost-function](https://www.kdnuggets.com/2020/05/5-concepts-gradient-descent-cost-function.html)
- [https://www.slideshare.net/hyeseunglee6/ch6-75888743?from_action=save](https://www.slideshare.net/hyeseunglee6/ch6-75888743?from_action=save) 
- [https://sacko.tistory.com/42https://twinw.tistory.com/247](https://sacko.tistory.com/42https://twinw.tistory.com/247) 

__`Next`__ : 2021.02.06 9:00 PM KST

- [http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/](https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/) 
- __Lecture 9: Generalization 1st part ( ~weight decay , 이동재)__ 
- 순서 고정 : `이동재` - `박희원` - `이찬주` - `민채정`

---

​	

![img1](/assets/img/CSC321/Lec 7.1.png)

​	

![img2](/assets/img/CSC321/Lec 7.2.png)

​	

![img3](/assets/img/CSC321/Lec 7.3.png)

​	

***



​	

