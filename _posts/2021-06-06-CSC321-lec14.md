---
title: 【Lecture 14】Recurrent Neural Networks
author: INEED COFFEE
date: 2021-06-06 14:00:00 +0800
categories: [ML/DL,Deep Learning]
tags: [deep learning,rnn,recurrent neural network]
toc: true
comments: true
typora-root-url: ../
---
# Course Study with [CSC321](https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/) 



### [2021.06.05]

__`Topic`__ : __Lecture 14: Recurrent Neural Networks (Hayden,James)__ 

__`Notes`__ : 

- [https://drive.google.com/file/d/1qP1_SBwEeFE8CQ0T_Pd9veb2H6JEVRbP/view?usp=sharing](https://drive.google.com/file/d/1qP1_SBwEeFE8CQ0T_Pd9veb2H6JEVRbP/view?usp=sharing) [Hayden]
- [https://drive.google.com/file/d/1otSFBwYQcOD1dgZqup5ZhQkvX1HIalIW/view?usp=sharing](https://drive.google.com/file/d/1otSFBwYQcOD1dgZqup5ZhQkvX1HIalIW/view?usp=sharing) [James]

__`Links`__ : 

- [https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L14%20Recurrent%20Neural%20Nets.pdf](https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L14%20Recurrent%20Neural%20Nets.pdf) (CSC321, EN)
- [https://blog.naver.com/PostView.nhn?blogId=winddori2002&logNo=221974391796](https://blog.naver.com/PostView.nhn?blogId=winddori2002&logNo=221974391796) (RNN computation flow, KR) 
- [https://curt-park.github.io/2017-03-26/yolo/](https://curt-park.github.io/2017-03-26/yolo/) (computation flow, KR)
- [http://bigdata.dongguk.ac.kr/lectures/TextMining/_book/%EC%96%B8%EC%96%B4-%EB%AA%A8%EB%8D%B8language-model.html](http://bigdata.dongguk.ac.kr/lectures/TextMining/_book/%EC%96%B8%EC%96%B4-%EB%AA%A8%EB%8D%B8language-model.html) (Language Modeling, KR)
- [https://gruuuuu.github.io/machine-learning/lstm-doc/](https://gruuuuu.github.io/machine-learning/lstm-doc/) (why tanh is used, not sigmoid nor relu ?, KR) 



---
> # Covered through study
>
> - __1.Introduction__ 
>   - Tasks predicting 'sequences'
>   - Neural Language Model to RNN
> - __2.Recurrent Neural Nets__ 
>   - unrolling network to understand like FFNN
>   - 3 examples of how parameter setting result in RNN
> - __3.Backprop Through Time__ 
>   - View as MLP backprop with unrolled computation-graph
>   - Comparing with MLP backprop
> - __4.Sequence Modeling (what tasks can RNN be applied)__ 
>   - Language Modeling
>   - Neural Machine Translation
>   - ~~Learning to Execute Programs~~ (removed)

​	

---

​			
# Recurrent Neural Networks

![img1](/assets/img/CSC321/Lec 14.10.png)

​	

![img2](/assets/img/CSC321/Lec 14.1.png)

​	

![img3](/assets/img/CSC321/Lec 14.2.png)

​	

![img4](/assets/img/CSC321/Lec 14.3.png)

​	

![img5](/assets/img/CSC321/Lec 14.4.png)

​	

![img6](/assets/img/CSC321/Lec 14.5.png)

​	

![img2](/assets/img/CSC321/Lec 14.6.png)

​	

![img3](/assets/img/CSC321/Lec 14.7.png)

​	

![img4](/assets/img/CSC321/Lec 14.8.png)

​	

![img5](/assets/img/CSC321/Lec 14.11.png)

​	

![img2](/assets/img/CSC321/Lec 14.12.png)


​	
![img2](/assets/img/CSC321/Lec 14.13.png)


![img2](/assets/img/CSC321/Lec 14.14.png)


​	
![img2](/assets/img/CSC321/Lec 14.15.png)


![img2](/assets/img/CSC321/Lec 14.16.png)


![img2](/assets/img/CSC321/Lec 14.9.png)


***

​	

