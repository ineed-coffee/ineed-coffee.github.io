<!DOCTYPE html><html lang="ko_KR" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="pv-cache-enabled" content="false"><meta name="generator" content="Jekyll v4.2.0" /><meta property="og:title" content="CSC321 스터디 진행 사항 (Toronto Univ. , Roger Grosse )" /><meta name="author" content="INEED COFFEE" /><meta property="og:locale" content="ko_KR" /><meta name="description" content="Course Study with CSC321" /><meta property="og:description" content="Course Study with CSC321" /><link rel="canonical" href="https://ineed-coffee.github.io/posts/CSC321-study-log/" /><meta property="og:url" content="https://ineed-coffee.github.io/posts/CSC321-study-log/" /><meta property="og:site_name" content="INEED COFFEE" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-01-04T15:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="CSC321 스터디 진행 사항 (Toronto Univ. , Roger Grosse )" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"datePublished":"2021-01-04T15:00:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://ineed-coffee.github.io/posts/CSC321-study-log/"},"description":"Course Study with CSC321","url":"https://ineed-coffee.github.io/posts/CSC321-study-log/","@type":"BlogPosting","author":{"@type":"Person","name":"INEED COFFEE"},"headline":"CSC321 스터디 진행 사항 (Toronto Univ. , Roger Grosse )","dateModified":"2021-06-27T22:19:01+09:00","@context":"https://schema.org"}</script><title>CSC321 스터디 진행 사항 (Toronto Univ. , Roger Grosse ) | INEED COFFEE</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/favicons/character.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">INEED COFFEE</a></div><div class="site-subtitle font-italic">Much more !</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/ineed-coffee" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['leey93ssu','gmail.com'].join('@')" aria-label="email" class="order-4" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-5" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>CSC321 스터디 진행 사항 (Toronto Univ. , Roger Grosse )</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>CSC321 스터디 진행 사항 (Toronto Univ. , Roger Grosse )</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> INEED COFFEE </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Mon, Jan 4, 2021, 3:00 PM +0900" prep="on" > Jan 4 <i class="unloaded">2021-01-04T15:00:00+09:00</i> </span></div><div> <span> <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Sun, Jun 27, 2021, 10:19 PM +0900" prefix="Updated " > Jun 27 <i class="unloaded">2021-06-27T22:19:01+09:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2488 words">13 min</span></div></div><div class="post-content"><h1 id="course-study-with-csc321">Course Study with <a href="https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/">CSC321</a></h1><h3 id="20210109">[2021.01.09]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> : <strong>Neural Network quick review to Gradient vanishing &amp; exploding problem</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li>[https://drive.google.com/file/d/15<em>-n3O7gaMyRTqq5-WC9hfms1Xtea2Jp/view?usp=sharing](https://drive.google.com/file/d/15</em>-n3O7gaMyRTqq5-WC9hfms1Xtea2Jp/view?usp=sharing)</ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><ul><li><a href="https://wikidocs.net/61375">https://wikidocs.net/61375</a><li><a href="https://m.blog.naver.com/PostView.nhn?blogId=pshkhh&amp;logNo=221203426679&amp;proxyReferer=https:%2F%2Fwww.google.com%2Fhttps://brunch.co.kr/@chris-song/39">https://m.blog.naver.com/PostView.nhn?blogId=pshkhh&amp;logNo=221203426679&amp;proxyReferer=https:%2F%2Fwww.google.com%2Fhttps://brunch.co.kr/@chris-song/39</a><li><a href="https://t-lab.tistory.com/14">https://t-lab.tistory.com/14</a><li><a href="https://aikorea.org/blog/rnn-tutorial-3/">https://aikorea.org/blog/rnn-tutorial-3/</a><li><a href="https://velog.io/@dscwinterstudy/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D2-5%EC%9E%A5-gnk6bhirc3">https://velog.io/@dscwinterstudy/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D2-5%EC%9E%A5-gnk6bhirc3</a><li><a href="https://m.blog.naver.com/worb1605/221187949828">https://m.blog.naver.com/worb1605/221187949828</a><li><a href="https://ganghee-lee.tistory.com/30">https://ganghee-lee.tistory.com/30</a><li><a href="https://heehehe-ds.tistory.com/entry/Deep-Learning-%EC%86%90%EC%8B%A4%ED%95%A8%EC%88%98loss-function-%EC%98%B5%ED%8B%B0%EB%A7%88%EC%9D%B4%EC%A0%80optimizer">https://heehehe-ds.tistory.com/entry/Deep-Learning-%EC%86%90%EC%8B%A4%ED%95%A8%EC%88%98loss-function-%EC%98%B5%ED%8B%B0%EB%A7%88%EC%9D%B4%EC%A0%80optimizer</a><li><a href="https://ydseo.tistory.com/41">https://ydseo.tistory.com/41</a><li><a href="https://cs224d.stanford.edu/notebooks/vanishing_grad_example.html">https://cs224d.stanford.edu/notebooks/vanishing_grad_example.html</a><li><a href="https://simonjisu.github.io/numpyseries/2018/03/14/rnnlstm2.html">https://simonjisu.github.io/numpyseries/2018/03/14/rnnlstm2.html</a><li><a href="https://mmuratarat.github.io/2019-02-07/bptt-of-rnn">https://mmuratarat.github.io/2019-02-07/bptt-of-rnn</a><li><a href="https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/">https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/</a></ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.01.16 9:30 PM KST</p><ul><li><a href="http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L15 Exploding and Vanishing Gradients.pdf">http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/</a><li><strong>Lecture 5: Multilayer Perceptrons (박희원) , Lecture 6: Backpropagation (이동재)</strong></ul><hr /><h3 id="20210116">[2021.01.16]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> : <strong>Lecture 5: Multilayer Perceptrons (박희원) , Lecture 6: Backpropagation (이동재)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li><a href="https://drive.google.com/file/d/1p446nFckVgzjhYFzZ7EABXLRX9Mq3QLN/view?usp=sharing">https://drive.google.com/file/d/1p446nFckVgzjhYFzZ7EABXLRX9Mq3QLN/view?usp=sharing</a> (희원)<li><a href="https://drive.google.com/file/d/1BydNGPxWEwRxiJobvu5dPq88xhRO2ypU/view?usp=sharing">https://drive.google.com/file/d/1BydNGPxWEwRxiJobvu5dPq88xhRO2ypU/view?usp=sharing</a> (동재)</ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><blockquote><p>Multilayer Perceptrons</p></blockquote><ul><li><a href="http://hleecaster.com/ml-perceptron-concept/">http://hleecaster.com/ml-perceptron-concept/</a><li><a href="http://blog.naver.com/PostView.nhn?blogId=apr407&amp;logNo=221238611771&amp;parentCategoryNo=&amp;categoryNo=55&amp;viewDate=&amp;isShowPopularPosts=true&amp;from=search">http://blog.naver.com/PostView.nhn?blogId=apr407&amp;logNo=221238611771&amp;parentCategoryNo=&amp;categoryNo=55&amp;viewDate=&amp;isShowPopularPosts=true&amp;from=search</a><li><a href="https://untitledtblog.tistory.com/27">https://untitledtblog.tistory.com/27</a><li><a href="https://choosunsick.github.io/post/neural_network_intro/">https://choosunsick.github.io/post/neural_network_intro/</a><li><a href="http://www.datamarket.kr/xe/board_LCmL04/26245">http://www.datamarket.kr/xe/board_LCmL04/26245</a></ul><blockquote><p>Backpropagation</p></blockquote><ul><li><a href="https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L06%20Backpropagation.pdf">https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L06%20Backpropagation.pdf</a><li><a href="https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/slides/lec8a.pdf">https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/slides/lec8a.pdf</a><li><a href="https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/slides/lec8b.pdf">https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/slides/lec8b.pdf</a></ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.01.23 9:00 PM KST</p><ul><li><a href="https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/">http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/</a><li><strong>Lecture 7: Optimization (이찬주)</strong></ul><hr /><h3 id="20210123">[2021.01.23]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> : <strong>Lecture 7: Optimization 1st part (이찬주)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li><a href="https://drive.google.com/file/d/1gq4tCKfcwQ_QYRO8XYhdR3Y3UTfJQXNd/view?usp=sharing">https://drive.google.com/file/d/1gq4tCKfcwQ_QYRO8XYhdR3Y3UTfJQXNd/view?usp=sharing</a></ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><ul><li><a href="https://hyunw.kim/blog/2017/11/01/Optimization.html">https://hyunw.kim/blog/2017/11/01/Optimization.html</a><li><a href="http://shuuki4.github.io/deep%20learning/2016/05/20/Gradient-Descent-Algorithm-Overview.html">Gradient Descent Optimization Algorithms 정리</a> , (shuuki4.github.io)</ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.01.30 9:00 PM KST</p><ul><li><a href="https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/">http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/</a><li><strong>Lecture 7: Optimization (from Momentum 민채정)</strong></ul><hr /><h3 id="20210130">[2021.01.30]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> <strong>:</strong> <strong>Lecture 7: Optimization (2nd , 민채정)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> : 업로드 예정</p><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><ul><li><a href="https://medium.com/analytics-vidhya/derivative-of-log-loss-function-for-logistic-regression-9b832f025c2d">Derivative of Logistic Regression</a><li><a href="https://ratsgo.github.io/convex%20optimization/2017/12/26/convexfunction/">what is convex function?</a><li><a href="https://www.kdnuggets.com/2020/05/5-concepts-gradient-descent-cost-function.html">cost-function</a><li><a href="https://www.slideshare.net/hyeseunglee6/ch6-75888743?from_action=save">https://www.slideshare.net/hyeseunglee6/ch6-75888743?from_action=save</a><li><a href="https://sacko.tistory.com/42https://twinw.tistory.com/247">https://sacko.tistory.com/42https://twinw.tistory.com/247</a></ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.02.06 9:00 PM KST</p><ul><li><a href="https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/">http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/</a><li><strong>Lecture 9: Generalization 1st part ( ~weight decay , 이동재)</strong><li>순서 고정 : <code class="language-plaintext highlighter-rouge">이동재</code> - <code class="language-plaintext highlighter-rouge">박희원</code> - <code class="language-plaintext highlighter-rouge">이찬주</code> - <code class="language-plaintext highlighter-rouge">민채정</code></ul><hr /><h3 id="20210206">[2021.02.06]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> <strong>:</strong> <strong>Lecture 9: Generalization (이동재)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li><a href="https://drive.google.com/file/d/1X-KzORli9CRrPun3qsMfREAr08cbLCWv/view?usp=sharing">https://drive.google.com/file/d/1X-KzORli9CRrPun3qsMfREAr08cbLCWv/view?usp=sharing</a></ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><ul><li><a href="https://blog.naver.com/mykepzzang/220837959160">https://blog.naver.com/mykepzzang/220837959160</a> (베이즈 에러 도출 과정 확률과 표준편차 참고자료)<li><a href="https://warm-uk.tistory.com/44">https://warm-uk.tistory.com/44</a> (BottleNeck 층을 활용한 Inception)<li><a href="https://munjeongkang.github.io/ANN2/">https://munjeongkang.github.io/ANN2/</a> (model capacity)<li><a href="https://light-tree.tistory.com/216">https://light-tree.tistory.com/216</a> (Weight decay , L1&amp;L2 regularizer)<li><a href="https://hyeonnii.tistory.com/353">https://hyeonnii.tistory.com/353</a> (Bayes Error)</ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.02.20 9:00 PM KST</p><ul><li><a href="https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/">http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/</a><li><strong>Lecture 11: Convolutional Networks (박희원)</strong></ul><hr /><h3 id="20210220">[2021.02.20]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> : <strong>Lecture 11: Convolutional Networks (박희원)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li><a href="https://drive.google.com/file/d/1F8j0ubTHnhKQ0nA8Qf7bysDkuaFlfmZ4/view?usp=sharing">https://drive.google.com/file/d/1F8j0ubTHnhKQ0nA8Qf7bysDkuaFlfmZ4/view?usp=sharing</a></ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><ul><li><a href="https://untitledtblog.tistory.com/150">https://untitledtblog.tistory.com/150</a><li><a href="https://underflow101.tistory.com/44">https://underflow101.tistory.com/44</a><li><a href="https://underflow101.tistory.com/25">https://underflow101.tistory.com/25</a><li><a href="https://excelsior-cjh.tistory.com/180">https://excelsior-cjh.tistory.com/180</a><li><a href="https://dsbook.tistory.com/59">https://dsbook.tistory.com/59</a><li><a href="https://nittaku.tistory.com/264">https://nittaku.tistory.com/264</a></ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.02.27 9:00 PM KST</p><ul><li><a href="https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/">http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/</a><li><strong>Lecture 12: Image Classification (이찬주)</strong></ul><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>1.두 데이터 셋 간단 소개 (MNIST , Caltech101)
2.Image NET 대회 간단 소개
3.Conv net 사이즈 구하는 방법 (표기 방법)
4.LeNET , AlexNET , GoogleNET , (LeNET , AlexNET 은 너무 깊게할 필요 없고 GoogleNET은 fully convolutional 이라는 의미가 뭔지)
</pre></table></code></div></div><hr /><h3 id="20210227">[2021.02.27]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> : <strong>Lecture 12: Image Classification (이찬주) , CNN misc part (이동재)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li><a href="https://drive.google.com/file/d/1GYaiD1fUVTdfW4P82oZz8oK5EJTm8xgX/view?usp=sharing">https://drive.google.com/file/d/1GYaiD1fUVTdfW4P82oZz8oK5EJTm8xgX/view?usp=sharing</a> (이찬주)<li><a href="https://drive.google.com/file/d/1npGyII1IWSrQQN_LGjtjK7RtgibJFvX-/view?usp=sharing">https://drive.google.com/file/d/1npGyII1IWSrQQN_LGjtjK7RtgibJFvX-/view?usp=sharing</a> (이동재)</ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><ul><li><a href="https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/slides/lec12.pdf">https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/slides/lec12.pdf</a> (Lecture 12 slide)<li><a href="https://yjjo.tistory.com/8">https://yjjo.tistory.com/8</a> (start of CNN , concept of receptive field , how to calculate Conv. net size)<li><a href="https://bskyvision.com/421">https://bskyvision.com/421</a> (all about AlexNet : info-share , ReLU , local response normalization)<li><a href="https://bskyvision.com/422">https://bskyvision.com/422</a> (what is top-5 , top-1 error ?)</ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.03.06 9:00 PM KST</p><ul><li><a href="https://m.blog.naver.com/laonple/220710707354">https://m.blog.naver.com/laonple/220710707354</a> (라온피플)<li><strong>Special Lecture : Inception , VGG Net , Res Net (이동재 , 민채정)</strong></ul><blockquote><p><strong>Google Net (이동재)</strong></p><ul><li>1X1 Convolution<li>Inception module (different kernel size , naive &amp; advanced)<li>global average pooling<li>auxilary classifier</ul></blockquote><blockquote><p><strong>VGG Net , Res Net (민채정)</strong></p><ul><li>important features of vgg net ( diff between 16 &amp; 19 ?)<li>concept of skip connection from Res Net<li>R-CNN , Fast R-CNN , Faster R-CNN 은 이번 파트 X</ul></blockquote><hr /><h3 id="20210306">[2021.03.06]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> : <strong>Lecture 12.3: GooLeNet (이동재)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li><a href="https://drive.google.com/file/d/1_PMmX5JODykn1q1667IbfDbSi5moxNY-/view?usp=sharing">https://drive.google.com/file/d/1_PMmX5JODykn1q1667IbfDbSi5moxNY-/view?usp=sharing</a> (이동재)</ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><ul><li><a href="https://blog.naver.com/laonple/220686328027">https://blog.naver.com/laonple/220686328027</a> (GooLeNet Lecture Note 1~5)<li><a href="https://bskyvision.com/539">https://bskyvision.com/539</a> (Inception V1 soft review)<li><a href="https://89douner.tistory.com/62">https://89douner.tistory.com/62</a> (concatenation in Inception module)<li><a href="https://jetsonaicar.tistory.com/16">https://jetsonaicar.tistory.com/16</a> (Global Average Pooling , explained)<li><a href="https://lv99.tistory.com/21">https://lv99.tistory.com/21</a> (1X1 Conv. layer , explained)</ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.03.13 9:00 PM KST</p><ul><li><p><strong>Special Lecture : VGG Net , Res Net (민채정)</strong></p><li><a href="https://blog.naver.com/laonple/220738560542">https://blog.naver.com/laonple/220738560542</a> (VGG Net [1] ~ VGG Net [2])<li><a href="https://blog.naver.com/laonple/220761052425">https://blog.naver.com/laonple/220761052425</a> (Res Net [1] ~ Res Net [3])</ul><blockquote><p><strong>Will Cover</strong></p><p><em>VGG Net</em> : using only 3X3 kernel ? (what is factorizing colvolution filter ?)</p><p><em>VGG Net</em> : how to deal with gradient vanish/exploding problem (pre-trained kernel initializing)</p><p><em>VGG Net</em> : technique on how-to train/test dataset (scale jittering) &lt;- 어려운 개념이니 간단하게만</p><p><em>Rest Net</em> : what is residual learning? ( Shortcut-connection? Identity mapping?)</p><p><em>Rest Net</em> : what features resnet team took from VGG? (common vs. diff)</p><p><em>Rest Net</em> : BottleNeck Layer (only for models with layers&gt;50)</p><p><em>Rest Net</em> : other experiment with CIFAR dataset (going for 1000 layers)</p></blockquote><p>​</p><hr /><p>​</p><h3 id="20210313">[2021.03.13]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> : <strong>Lecture 12.4: VGG , ResNet (민채정,이동재)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li><a href="https://drive.google.com/file/d/1HMu1LWBzk_FtQoB9m-0ti03_dMNYo3YG/view?usp=sharing">https://drive.google.com/file/d/1HMu1LWBzk_FtQoB9m-0ti03_dMNYo3YG/view?usp=sharing</a></ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><ul><li><a href="https://blog.naver.com/laonple/220710707354">https://blog.naver.com/laonple/220710707354</a> (VGG : Conv. Factorizing)<li><a href="https://brunch.co.kr/@kmbmjn95/37">https://brunch.co.kr/@kmbmjn95/37</a> (ResNet : how ‘residual’ idea came up)<li><a href="https://www.stand-firm-peter.me/2020/09/26/resnet/">https://www.stand-firm-peter.me/2020/09/26/resnet/</a> (ResNet : 최강 자료1. 모든 설명 다 있음)<li><a href="https://www.stand-firm-peter.me/2020/09/30/resnet_2/">https://www.stand-firm-peter.me/2020/09/30/resnet_2/</a> (ResNet : 최강 자료2. 모든 설명 다 있음)<li><a href="https://ratsgo.github.io/deep%20learning/2017/10/09/CNNs/">https://ratsgo.github.io/deep%20learning/2017/10/09/CNNs/</a> (ResNet : DenseNet 언급)</ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.03.20 9:00 PM KST</p><ul><li><p><strong>Object Detection : R-CNN , SPPNET (Hayden)</strong></p><li><p><a href="https://blog.naver.com/laonple/220731472214">https://blog.naver.com/laonple/220731472214</a> (GooLeNet [6])</p></ul><blockquote><p><strong>Will Cover</strong></p><ul><li>Object Classification VS. Object Detection ?<ul><li>Bounding Box , mAP , IOU</ul><li>What is R-CNN ?<ul><li>SIFT , HOG<li>Selective search</ul><li>How Berkeley team applied R-CNN ?<ul><li>PASCAL VOL<li>fine-tuning</ul><li>Limits of R-CNN &amp; How SPPNet came up<ul><li>dealing with fixed input size<li>how many crops/warps</ul></ul></blockquote><ul><li>순서 변경 : <code class="language-plaintext highlighter-rouge">이동재</code> - <code class="language-plaintext highlighter-rouge">민채정</code> - <code class="language-plaintext highlighter-rouge">박희원</code> - <code class="language-plaintext highlighter-rouge">이찬주</code> - <code class="language-plaintext highlighter-rouge">김진원</code></ul><hr /><p>​</p><h3 id="20210320">[2021.03.20]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> : <strong>Lecture 13: Object Detection, R-CNN &amp; SPPNET (Hayden)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li><a href="https://drive.google.com/file/d/1CymQUZRUMwj4uCGWzFqZj48_HEP8scNo/view?usp=sharing">https://drive.google.com/file/d/1CymQUZRUMwj4uCGWzFqZj48_HEP8scNo/view?usp=sharing</a></ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><ul><li><a href="https://woosikyang.github.io/fast-rcnn.html">https://woosikyang.github.io/fast-rcnn.html</a><li><a href="https://nuggy875.tistory.com/21">https://nuggy875.tistory.com/21</a><li><a href="https://ganghee-lee.tistory.com/35">https://ganghee-lee.tistory.com/35</a><li><a href="https://blog.naver.com/PostView.nhn?blogId=isu112600&amp;logNo=221583808984">https://blog.naver.com/PostView.nhn?blogId=isu112600&amp;logNo=221583808984</a><li><a href="https://woosikyang.github.io/fast-rcnn.html">https://woosikyang.github.io/fast-rcnn.html</a></ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.03.27 9:00 PM KST</p><ul><li><strong>Object Detection : R-CNN details (Chanju, James)</strong><li><a href="https://blog.naver.com/laonple/220731472214">https://blog.naver.com/laonple/220731472214</a> ( (GooLeNet [6])</ul><blockquote><p><strong>Will Cover</strong></p><ul><li>R-CNN : Background<ul><li>Computer Vision , selective search , SIFT , HOG , DPM</ul><li>R-CNN : Architecture<ul><li>3-modules</ul><li>R-CNN : How to test ? (detect , forward)<ul><li>NMS</ul><li>R-CNN : How to evaluate?<ul><li>mAP , different metrics</ul><li>R-CNN : How to train?<ul><li>different IOU threshold<li>Bbox regressor understanding</ul><li>R-CNN : Limits</ul></blockquote><hr /><p>​</p><h3 id="20210327">[2021.03.27]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> : <strong>Lecture 13.2: Object Detection : R-CNN details (Chanju, James)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li><a href="https://drive.google.com/file/d/12qj8R53HCYFz8ZcKlukv1pKEM-rM5_4e/view?usp=sharing">https://drive.google.com/file/d/12qj8R53HCYFz8ZcKlukv1pKEM-rM5_4e/view?usp=sharing</a> [James]</ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><ul><li><a href="https://arxiv.org/pdf/1311.2524.pdf">https://arxiv.org/pdf/1311.2524.pdf</a> (original r-cnn thesis)<li><a href="https://wiserloner.tistory.com/1174">https://wiserloner.tistory.com/1174</a> (r-cnn background, selective search details)<li><a href="https://lilianweng.github.io/lil-log/2017/12/31/object-recognition-for-dummies-part-3.html#model-workflow">https://lilianweng.github.io/lil-log/2017/12/31/object-recognition-for-dummies-part-3.html#model-workflow</a> (hard negative mining)<li><a href="https://nuggy875.tistory.com/21">https://nuggy875.tistory.com/21</a> (how to train each modules)<li><a href="https://dyndy.tistory.com/275">https://dyndy.tistory.com/275</a> (NMS)<li><a href="https://pacientes.github.io/posts/2021/02/ml_ap_map/">https://pacientes.github.io/posts/2021/02/ml_ap_map/</a> (Confidence score)<li><a href="http://blog.naver.com/PostView.nhn?blogId=sogangori&amp;logNo=221224276320">http://blog.naver.com/PostView.nhn?blogId=sogangori&amp;logNo=221224276320</a> mAP<li><a href="https://eehoeskrap.tistory.com/183">https://eehoeskrap.tistory.com/183</a> (end-to-end)</ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.04.03 9:00 PM KST</p><ul><li><strong>Object Detection : SPPNET details, Fast-RCNN overview (Chanju, James)</strong><li><a href="https://blog.naver.com/laonple/220731472214">https://blog.naver.com/laonple/220731472214</a> ( GooLeNet [6])<li><a href="https://blog.naver.com/laonple/220776743537">https://blog.naver.com/laonple/220776743537</a> ( ResNet [4])</ul><blockquote><p><strong>Will Cover</strong></p><ul><li>SPP Net :<ul><li>What’s improved from R-CNN ? (idea, keywords)<li>SPP Net flow (rough) (compared with R-CNN)<li>SPP layer details (bin, BoW, how to calculate output)<li>Practical training (Single-size, Multi-size training)<li>Performance in fields (Classification, Detection)<li>SPP Net Limits</ul><li>Fast R-CNN :<ul><li>what’s improved from SPP Net ? (idea, keywords)<li>Fast R-CNN flow (rough) (compared with SPP Net)<li>training Fast R-CNN (multi-task loss function, Hierarchical Sampling)<li>test methods (truncated SVD)<li>Fast R-CNN Limits</ul></ul></blockquote><p><em>Future models of object detection :</em> <code class="language-plaintext highlighter-rouge">SPPNet</code> , <code class="language-plaintext highlighter-rouge">Fast R-CNN</code> , <code class="language-plaintext highlighter-rouge">Faster R-CNN</code> , <code class="language-plaintext highlighter-rouge">YOLO v1</code></p><hr /><p>​</p><h3 id="20210403">[2021.04.03]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> : <strong>Lecture 13.3: Object Detection : SPPNET overview &amp; details (Chanju, James)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li><a href="https://drive.google.com/file/d/1IQHx6BPhMwCURbBuw6QBcBeLk8YSUnZg/view?usp=sharing">https://drive.google.com/file/d/1IQHx6BPhMwCURbBuw6QBcBeLk8YSUnZg/view?usp=sharing</a> [Chanju]<li><a href="https://drive.google.com/file/d/1bQAmtjUexd1lbpZgRB_sKC8VOwPMs064/view?usp=sharing">https://drive.google.com/file/d/1bQAmtjUexd1lbpZgRB_sKC8VOwPMs064/view?usp=sharing</a> [James]</ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><blockquote><p>SPP Net</p></blockquote><ul><li><a href="https://arxiv.org/pdf/1406.4729.pdf">https://arxiv.org/pdf/1406.4729.pdf</a> (original spp net thesis)<li><a href="https://driip.me/5743aed5-c630-4900-b367-9987a088661a">https://driip.me/5743aed5-c630-4900-b367-9987a088661a</a> (what is BoW approach in image?)<li><a href="https://n1094.tistory.com/30">https://n1094.tistory.com/30</a> (spp layer performance in classificaton &amp; detection)<li><a href="https://blog.naver.com/laonple/220731472214">https://blog.naver.com/laonple/220731472214</a> (Laon people, 내용 생략 심함)<li><a href="https://yeomko.tistory.com/14">https://yeomko.tistory.com/14</a> (SPPnet 전반적 흐름 &amp; 설명)<li><a href="https://www.youtube.com/watch?v=i0lkmULXwe0">https://www.youtube.com/watch?v=i0lkmULXwe0</a> (SPPnet 논문 강의 : 고려대학교 연구실)<li><a href="https://89douner.tistory.com/89">https://89douner.tistory.com/89</a> (SPPnet 보충 설명 , 자세한)</ul><blockquote><p>Fast R-CNN</p></blockquote><ul><li><a href="https://arxiv.org/pdf/1504.08083.pdf">https://arxiv.org/pdf/1504.08083.pdf</a> (original fast r-cnn thesis)<li><a href="https://fintecuriosity-11.tistory.com/73">https://fintecuriosity-11.tistory.com/73</a> (ablation study)<li><a href="https://yeomko.tistory.com/15">https://yeomko.tistory.com/15</a> (how is end-to-end training possible?)<li><a href="https://deepsense.ai/region-of-interest-pooling-explained/">https://deepsense.ai/region-of-interest-pooling-explained/</a> (spp vs roi pooling)</ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.04.10 9:00 PM KST</p><ul><li><strong>Object Detection : Fast R-CNN overview, details (Jaden , James)</strong><li><strong>Fast R-CNN fine-tuning practice</strong></ul><blockquote><p><strong>Will Cover</strong></p><ul><li>Fast R-CNN :<ul><li>what’s improved from SPP Net ? (idea, keywords)<ul><li>end-to-end<li>softmax replacing svm<li>ROI-pooling</ul><li>Fast R-CNN flow<ul><li>comapred with previous models</ul><li>training Fast R-CNN<ul><li>multi-task loss function<li>Hierarchical Sampling ( vs. region-wise sampling)</ul><li>test methods (truncated SVD)<li>Fast R-CNN Limits</ul><li>ResNet fine-tuning source code<ul><li><a href="https://github.com/polospeter/TensorFlow-Advanced-Techniques-Specialization/blob/main/Course%203%20-%20Advanced%20computer%20vision%20with%20Tensorflow/Week%201/C3_W1_Lab_2_Transfer_Learning_CIFAR_10.ipynb">https://github.com/polospeter/TensorFlow-Advanced-Techniques-Specialization/blob/main/Course%203%20-%20Advanced%20computer%20vision%20with%20Tensorflow/Week%201/C3_W1_Lab_2_Transfer_Learning_CIFAR_10.ipynb</a></ul></ul></blockquote><hr /><p>​</p><h3 id="20210410">[2021.04.10]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> : <strong>Lecture 13.4: Object Detection : Fast R-CNN details, ResNet fine-tuning practice (James , Jaden)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li><a href="https://drive.google.com/file/d/1ari0YxYTqaH9mky2pKkPOO9p15gX1EBS/view?usp=sharing">https://drive.google.com/file/d/1ari0YxYTqaH9mky2pKkPOO9p15gX1EBS/view?usp=sharing</a> [James]<li><a href="https://drive.google.com/drive/folders/18WZeNJSrlOti07epXNy75Ws1s6U-Y-Q9?usp=sharing">https://drive.google.com/drive/folders/18WZeNJSrlOti07epXNy75Ws1s6U-Y-Q9?usp=sharing</a> [Jaden]</ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><blockquote><p>Fast R-CNN</p></blockquote><ul><li><a href="https://arxiv.org/pdf/1504.08083.pdf">https://arxiv.org/pdf/1504.08083.pdf</a> (original fast r-cnn thesis)<li><a href="https://fintecuriosity-11.tistory.com/73">https://fintecuriosity-11.tistory.com/73</a> (ablation study)<li><a href="https://yeomko.tistory.com/15">https://yeomko.tistory.com/15</a> (how is end-to-end training possible?)<li><a href="https://deepsense.ai/region-of-interest-pooling-explained/">https://deepsense.ai/region-of-interest-pooling-explained/</a> (spp vs roi pooling)<li><a href="https://ratsgo.github.io/deep%20learning/2017/04/05/CNNbackprop/">https://ratsgo.github.io/deep%20learning/2017/04/05/CNNbackprop/</a> (backprops in CNN layer)</ul><blockquote><p>Res Net fine-tuning code</p></blockquote><ul><li><a href="https://www.tensorflow.org/hub/tutorials/tf2_object_detection">https://www.tensorflow.org/hub/tutorials/tf2_object_detection</a><li><a href="https://detectron2.readthedocs.io/en/latest/_modules/detectron2/modeling/roi_heads/fast_rcnn.html">https://detectron2.readthedocs.io/en/latest/_modules/detectron2/modeling/roi_heads/fast_rcnn.html</a><li><a href="https://github.com/facebookresearch/detectron2/blob/master/detectron2/modeling/roi_heads/fast_rcnn.py">https://github.com/facebookresearch/detectron2/blob/master/detectron2/modeling/roi_heads/fast_rcnn.py</a><li><a href="https://github.com/rbgirshick/py-faster-rcnn">https://github.com/rbgirshick/py-faster-rcnn</a></ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.04.24 9:00 PM KST</p><ul><li><strong>Object Detection : Faster R-CNN overview,details (James)</strong></ul><blockquote><p><strong>Will Cover</strong></p><ul><li>자주 쓰게 될 서브 패키지 및 객체들<li>3가지 모델 작성 법<li>학습&amp;테스트 과정 및 설정</ul></blockquote><hr /><p>​</p><h3 id="20210424">[2021.04.24]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> : <strong>Special Course 1.DNN_practice &amp; keras overview from Colab (James)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li><a href="https://colab.research.google.com/drive/1hgquBEms7U-ZOff2x4OYy2Xzd8WZed5z?usp=sharing">https://colab.research.google.com/drive/1hgquBEms7U-ZOff2x4OYy2Xzd8WZed5z?usp=sharing</a> [James]</ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><ul><li><p><a href="https://keras.io/api">도큐먼트 짱</a></p><li><p><a href="https://wikidocs.net/106897">https://wikidocs.net/106897</a> (3-API)</p><li><p><a href="https://jjeongil.tistory.com/953">https://jjeongil.tistory.com/953</a> (evaluate)</p><li><p><a href="https://data-newbie.tistory.com/644">https://data-newbie.tistory.com/644</a> (performance visualization)</p></ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.05.01 9:00 PM KST</p><ul><li><strong>Inception module implementation from keras in Colab (Chloe)</strong></ul><blockquote><ul><li>how to build Inception module with keras using Functional API method?</ul></blockquote><hr /><p>​</p><h3 id="20210501">[2021.05.01]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> : <strong>Special Course 2. Keras overview &amp; implementation of Inception block on Colab (James)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li><a href="https://colab.research.google.com/drive/1hgquBEms7U-ZOff2x4OYy2Xzd8WZed5z?usp=sharing">https://colab.research.google.com/drive/1hgquBEms7U-ZOff2x4OYy2Xzd8WZed5z?usp=sharing</a> [James]</ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><ul><li><a href="https://keras.io/api">도큐먼트 짱</a><li><a href="https://wikidocs.net/106897">https://wikidocs.net/106897</a> (3-API)<li><a href="https://jjeongil.tistory.com/953">https://jjeongil.tistory.com/953</a> (evaluate)<li><a href="https://data-newbie.tistory.com/644">https://data-newbie.tistory.com/644</a> (performance visualization)<li><a href="https://nevfiasco.tistory.com/6">https://nevfiasco.tistory.com/6</a> (Inception block implementation)</ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.05.08 9:00 PM KST</p><ul><li><strong>Object Detection: Faster R-CNN (Chloe, James)</strong></ul><blockquote><ol><li><strong>What’s improved? (or suggested?)</strong></ol><ul><li>키워드별로 개념만, 뒤에 세부내용이 별도로 나옴<li><code class="language-plaintext highlighter-rouge">RPN</code> , region proposal networks ( kind of FCN?)<li>Pyramids of images VS. Pyramids of filters VS. <code class="language-plaintext highlighter-rouge">Pyramids of Anchors</code></ul><ol><li><strong>Model architecture &amp; Forward-pass (brief check)</strong></ol><ul><li>마찬가지로 간단히<li>how a single image passs through model</ul><ol><li><strong>All about RPN</strong></ol><ul><li>자세히<li>Inputs &amp; Outputs<li>Anchor Box<ul><li>what is Anchor box &amp; what does translation-invariant means<li>how to refer anchor box to regression</ul><li>Loss<ul><li>what loss function is defined on RPN?</ul><li>Train<ul><li>how to train RPN?</ul></ul><ol><li><strong>How RPN and Detector share feature maps?</strong></ol><ul><li>alternating training?</ul><ol><li><strong>Implementation details</strong></ol><ul><li>가능한 정도만<li>used scales, anchor types</ul></blockquote><hr /><p>​</p><h3 id="20210508">[2021.05.08]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> : <strong>Lecture 13.5: Object Detection Faster R-CNN part1 (Chloe, James)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li><a href="https://drive.google.com/file/d/1--1Wj2JcrLcxMHPWoJNo24sPg2TAa-Go/view?usp=sharing">https://drive.google.com/file/d/1–1Wj2JcrLcxMHPWoJNo24sPg2TAa-Go/view?usp=sharing</a> [Chloe]<li><a href="https://drive.google.com/file/d/16bjfABuBK1J-ejQRYNgOLjT2Z-iiqiu2/view?usp=sharing">https://drive.google.com/file/d/16bjfABuBK1J-ejQRYNgOLjT2Z-iiqiu2/view?usp=sharing</a> [James]</ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><ul><li><a href="https://arxiv.org/pdf/1506.01497.pdf">https://arxiv.org/pdf/1506.01497.pdf</a> (Faster R-CNN original thesis)<li><a href="https://www.youtube.com/watch?v=46SjJbUcO-c&amp;t=1451s">https://www.youtube.com/watch?v=46SjJbUcO-c&amp;t=1451s</a> (기초개념 참고 유튜브 영상)<li><a href="https://deep-learning-study.tistory.com/464">https://deep-learning-study.tistory.com/464</a> (In/Out of RPN picture)<li><a href="https://herbwood.tistory.com/10">https://herbwood.tistory.com/10</a> (Training RPN details, KR)<li><a href="https://www.telesens.co/2018/03/11/object-detection-and-classification-using-r-cnns/">https://www.telesens.co/2018/03/11/object-detection-and-classification-using-r-cnns/</a> (Training RPN details, EN)<li><a href="https://herbwood.tistory.com/11?category=867198">https://herbwood.tistory.com/11?category=867198</a> (코드로 이해하는 RPN)<li><a href="https://medipixel.github.io/post/2019-06-14-anchor-target/#ref_7">https://medipixel.github.io/post/2019-06-14-anchor-target/#ref_7</a> (코드로 이해하는 RPN loss)<li><a href="https://ganghee-lee.tistory.com/39">https://ganghee-lee.tistory.com/39</a> (FCN 참고자료 1)<li><a href="https://medium.com/hyunjulie/1%ED%8E%B8-semantic-segmentation-%EC%B2%AB%EA%B1%B8%EC%9D%8C-4180367ec9cb">https://medium.com/hyunjulie/1%ED%8E%B8-semantic-segmentation-%EC%B2%AB%EA%B1%B8%EC%9D%8C-4180367ec9cb</a> (FCN 참고자료 2)</ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.05.15 9:00 PM KST</p><ul><li><strong>Object Detection: Faster R-CNN part2 (Hayden, James)</strong></ul><blockquote><ul><li><strong>All about RPN</strong><li>Train (how to train RPN?)<li><strong>How RPN and Detector share feature maps?</strong><ul><li>4-step alternating training</ul><li><strong>Implementation details</strong><ul><li>가능한 정도만<li>used scales, anchor types</ul></ul><p>+ <strong>multibox approach (pyramids of filters)</strong></p><p>+ <strong>understanding regression loss of RPN</strong></p></blockquote><hr /><p><strong><code class="language-plaintext highlighter-rouge">스터디 RULE 수정</code></strong></p><ul><li>월/화 : 순서 변경이 필요한 팀원의 경우 화요일 저녁 전까지 다른 팀원에게 요청.<li>수: 해당 주 담당 팀원은 진행 정도 및 별도 준비가 필요한 부분을 James에게 전달.</ul><hr /><p>​</p><h3 id="20210515">[2021.05.15]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> : <strong>Lecture 13.5: Object Detection Faster R-CNN part2 (Hayden, James)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li><a href="https://drive.google.com/file/d/1UdzLboCNc1Sda4ns83RVS-ar-JhcVCZl/view?usp=sharing">https://drive.google.com/file/d/1UdzLboCNc1Sda4ns83RVS-ar-JhcVCZl/view?usp=sharing</a> [Hayden]<li><a href="https://drive.google.com/file/d/1OhM4QieuKMh_Nlv5WkWv0iZ4-MXBV_IK/view?usp=sharing">https://drive.google.com/file/d/1OhM4QieuKMh_Nlv5WkWv0iZ4-MXBV_IK/view?usp=sharing</a> [James]</ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><ul><li><a href="https://herbwood.tistory.com/10">https://herbwood.tistory.com/10</a> (Training RPN details, KR)<li><a href="https://www.telesens.co/2018/03/11/object-detection-and-classification-using-r-cnns/">https://www.telesens.co/2018/03/11/object-detection-and-classification-using-r-cnns/</a> (Training RPN details, EN)<li><a href="https://nuggy875.tistory.com/33">https://nuggy875.tistory.com/33</a> (Lreg term of RPN loss)<li><a href="https://ganghee-lee.tistory.com/37">https://ganghee-lee.tistory.com/37</a> (4-step alternating trainging of Faster R-CNN)<li><a href="https://ratsgo.github.io/deep%20learning/2017/04/05/CNNbackprop/">https://ratsgo.github.io/deep%20learning/2017/04/05/CNNbackprop/</a> (remind of back-prop of maxpool layer)</ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.05.22 9:00 PM KST</p><ul><li><strong>Object Detection: YOLO v1 (Chanju, James)</strong></ul><blockquote><ul><li></ul></blockquote><hr /><p>​</p><h3 id="20210523">[2021.05.23]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> : <strong>Programmers ML Dev-matching 참여 (전원)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li><a href="https://programmers.co.kr/competitions/1109/2021-machinelearning">https://programmers.co.kr/competitions/1109/2021-machinelearning</a> [Programmers Link]</ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><ul><li><code class="language-plaintext highlighter-rouge">None</code></ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.05.29 9:00 PM KST</p><ul><li><strong>Object Detection: YOLO v1 (Chloe, Chanju, James)</strong></ul><blockquote><ul><li><strong>What’s improved? (or suggested?)</strong><ul><li>object-detection as single-regression problem<li>three benefits over traditional models</ul><li><strong>Architecture &amp; Computation flow</strong><ul><li>network design<li>how raw image pass-through model (checking in/out of every layer)</ul><li><strong>Train &amp; Inference</strong><ul><li>understanding each term of sum-squared error<li>using <code class="language-plaintext highlighter-rouge">λcoord</code> , <code class="language-plaintext highlighter-rouge">λnoobj</code> parameters</ul><li><strong>Limits &amp; Comparison to other previous models</strong><ul><li>limits : spatial constraint, small-object problem, coarse features, loss-balance<li>comparison : <code class="language-plaintext highlighter-rouge">DPM</code> , <code class="language-plaintext highlighter-rouge">Deep MultiBox</code> , <code class="language-plaintext highlighter-rouge">OverFeat</code> , <code class="language-plaintext highlighter-rouge">MultiGrasp</code> 제외</ul></ul></blockquote><hr /><p>​</p><h3 id="20210529">[2021.05.29]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> : <strong>Object Detection: YOLO v1 (Chloe, Chanju, James)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li><a href="https://drive.google.com/file/d/1WSqIcKwjyRALc4T3v0L3sBim5XuiSjkV/view?usp=sharing">https://drive.google.com/file/d/1WSqIcKwjyRALc4T3v0L3sBim5XuiSjkV/view?usp=sharing</a> [Chanju]<li><a href="https://drive.google.com/file/d/18ITsaPJeyCBJVEUfjxaFFfgXxoiXjxk6/view?usp=sharing">https://drive.google.com/file/d/18ITsaPJeyCBJVEUfjxaFFfgXxoiXjxk6/view?usp=sharing</a> [James]<li><a href="https://drive.google.com/file/d/1-61pnmfN_boV-Xgif2br8nUWN2hEh6Ge/view?usp=sharing">https://drive.google.com/file/d/1-61pnmfN_boV-Xgif2br8nUWN2hEh6Ge/view?usp=sharing</a> [Chloe]</ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><ul><li><a href="https://arxiv.org/pdf/1506.02640.pdf">https://arxiv.org/pdf/1506.02640.pdf </a> (원 논문)<li><a href="https://jonathan-hui.medium.com/real-time-object-detection-with-yolo-yolov2-28b1b93e2088">https://jonathan-hui.medium.com/real-time-object-detection-with-yolo-yolov2-28b1b93e2088</a> (how output of final fc layer is tensor, not vector? =&gt; reshape, EN)<li><a href="https://curt-park.github.io/2017-03-26/yolo/">https://curt-park.github.io/2017-03-26/yolo/</a> (computation flow, KR)<li><a href="https://kevin970401.github.io/cnn/2019/08/19/detection.html">https://kevin970401.github.io/cnn/2019/08/19/detection.html</a> (yolo limits, KR)</ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.06.05 9:00 PM KST</p><ul><li><strong>Recurrent Neural Network (Hayden, James)</strong></ul><blockquote><ul><li><p><a href="https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L14%20Recurrent%20Neural%20Nets.pdf">https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L14%20Recurrent%20Neural%20Nets.pdf</a></p><li><strong>1.Introduction</strong><ul><li>Tasks predicting ‘sequences’<li>Neural Language Model to RNN</ul><li><strong>2.Recurrent Neural Nets</strong><ul><li>unrolling network to understand like FFNN<li>3 examples of how parameter setting result in RNN</ul><li><strong>3.Backprop Through Time</strong><ul><li>View as MLP backprop with unrolled computation-graph<li>Comparing with MLP backprop</ul><li><strong>4.Sequence Modeling (what tasks can RNN be applied)</strong><ul><li>Language Modeling<li>Neural Machine Translation<li>Learning to Execute Programs</ul></ul></blockquote><p>​</p><hr /><p>​</p><h3 id="20210605">[2021.06.05]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> : <strong>Recurrent Neural Networks (Hayden, James)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li><a href="https://drive.google.com/file/d/1qP1_SBwEeFE8CQ0T_Pd9veb2H6JEVRbP/view?usp=sharing">https://drive.google.com/file/d/1qP1_SBwEeFE8CQ0T_Pd9veb2H6JEVRbP/view?usp=sharing</a> [Hayden]<li><a href="https://drive.google.com/file/d/1otSFBwYQcOD1dgZqup5ZhQkvX1HIalIW/view?usp=sharing">https://drive.google.com/file/d/1otSFBwYQcOD1dgZqup5ZhQkvX1HIalIW/view?usp=sharing</a> [James]</ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><ul><li><a href="https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L14%20Recurrent%20Neural%20Nets.pdf">https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L14%20Recurrent%20Neural%20Nets.pdf</a> (CSC321, EN)<li><a href="https://blog.naver.com/PostView.nhn?blogId=winddori2002&amp;logNo=221974391796">https://blog.naver.com/PostView.nhn?blogId=winddori2002&amp;logNo=221974391796</a> (RNN computation flow, KR)<li><a href="https://curt-park.github.io/2017-03-26/yolo/">https://curt-park.github.io/2017-03-26/yolo/</a> (computation flow, KR)<li><a href="http://bigdata.dongguk.ac.kr/lectures/TextMining/_book/%EC%96%B8%EC%96%B4-%EB%AA%A8%EB%8D%B8language-model.html">http://bigdata.dongguk.ac.kr/lectures/TextMining/_book/%EC%96%B8%EC%96%B4-%EB%AA%A8%EB%8D%B8language-model.html</a> (Language Modeling, KR)<li><a href="https://gruuuuu.github.io/machine-learning/lstm-doc/">https://gruuuuu.github.io/machine-learning/lstm-doc/</a> (why tanh is used, not sigmoid nor relu ?, KR)</ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.06.19 9:00 PM KST</p><ul><li><strong>Long Short Term Memory Networks (Jaden, James)</strong></ul><blockquote><ul><li><strong>1.Introduction</strong><ul><li>Long-Term Dependency (gradient vanishing/exploding)<li>introduction to 3 gates</ul><li><strong>2.LSTM forward computation flow</strong><ul><li>what is calculated at each gate<li>summarized behavior table</ul><li><strong>3.LSTM BPTT flow</strong><ul><li>what to update?<li>how cell-state is safe from GV,GE ?</ul><li><strong>4.Quick LSTM example (Tensorflow)</strong><ul><li>Tensorflow Time-Series Tutorial</ul></ul></blockquote><p>​</p><hr /><p>​</p><h3 id="20210619">[2021.06.19]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> : <strong>Long Short Term Memory (Jaden, James)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li><a href="https://drive.google.com/file/d/1aPc-tj2W3QxV3R_mPKn6V-LjWLxpnZto/view?usp=sharing">https://drive.google.com/file/d/1aPc-tj2W3QxV3R_mPKn6V-LjWLxpnZto/view?usp=sharing</a> [Jaden]<li><a href="https://drive.google.com/file/d/1Y3s4ZuPlsrW0PyZgQc2pVMyoLAzBvWz-/view?usp=sharing">https://drive.google.com/file/d/1Y3s4ZuPlsrW0PyZgQc2pVMyoLAzBvWz-/view?usp=sharing</a> [James]</ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><ul><li><a href="https://brunch.co.kr/@chris-song/9">https://brunch.co.kr/@chris-song/9</a> (Long Term Dependency, KR)<li><a href="https://wegonnamakeit.tistory.com/7">https://wegonnamakeit.tistory.com/7</a> (introduction to 3-gates, KR)<li><a href="https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/">https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/</a> (LSTM BPTT figure, KR)<li><a href="https://brunch.co.kr/@chris-song/9">https://brunch.co.kr/@chris-song/9</a> (BPTT equation, KR)<li><a href="http://blog.naver.com/PostView.nhn?blogId=apr407&amp;logNo=221237917815&amp;parentCategoryNo=&amp;categoryNo=58&amp;viewDate=&amp;isShowPopularPosts=true&amp;from=search">http://blog.naver.com/PostView.nhn?blogId=apr407&amp;logNo=221237917815&amp;parentCategoryNo=&amp;categoryNo=58&amp;viewDate=&amp;isShowPopularPosts=true&amp;from=search</a> (Vectorized Notation, KR)<li><a href="https://wegonnamakeit.tistory.com/7">https://wegonnamakeit.tistory.com/7</a> (Peephole LTSM, KR)<li><a href="https://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/slides/lec16.pdf">https://www.cs.toronto.edu/~rgrosse/courses/csc321_2018/slides/lec16.pdf</a> (Gate behavior table, EN)<li><a href="https://tykimos.github.io/2017/04/09/RNN_Layer_Talk/">https://tykimos.github.io/2017/04/09/RNN_Layer_Talk/</a> (LSTM coding)</ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.06.26 9:00 PM KST</p><ul><li><strong>GRU part1(James)</strong></ul><blockquote><ul><li><strong>LSTM review &amp; QnA</strong><li><strong>1.Introduction</strong><ul><li>background - complex structure of LSTM<li>introduction to 2 gates - Reset gate, Update gate</ul><li><strong>2.GRU forward computation flow</strong><ul><li>what is calculated at each gate (how is it diff from LSTM?)<li>understanding flow as human language</ul></ul></blockquote><p>​</p><hr /><p>​</p><h3 id="20210626">[2021.06.26]</h3><p><strong><code class="language-plaintext highlighter-rouge">Topic</code></strong> : <strong>Gated Recurrent Units (James)</strong></p><p><strong><code class="language-plaintext highlighter-rouge">Notes</code></strong> :</p><ul><li><a href="https://drive.google.com/file/d/14GIdsLiTJgbYtU--aCi11sev_s8GHSYq/view?usp=sharing">https://drive.google.com/file/d/14GIdsLiTJgbYtU–aCi11sev_s8GHSYq/view?usp=sharing</a> [James]</ul><p><strong><code class="language-plaintext highlighter-rouge">Links</code></strong> :</p><ul><li><a href="https://wiserloner.tistory.com/1112">https://wiserloner.tistory.com/1112</a> (Why GRU was developed? , KR)<li><a href="https://yjjo.tistory.com/18">https://yjjo.tistory.com/18</a> (introduction to gates in GRU , KR)<li><a href="https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;blogId=winddori2002&amp;logNo=221992543837">https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;blogId=winddori2002&amp;logNo=221992543837</a> (Computation flow details , KR)<li><a href="https://medium.com/@mihirkhandekar/forward-and-backpropagation-in-grus-derived-deep-learning-5764f374f3f5">https://medium.com/@mihirkhandekar/forward-and-backpropagation-in-grus-derived-deep-learning-5764f374f3f5</a> (BPTT in GRU , EN)<li><a href="https://wikidocs.net/106473">https://wikidocs.net/106473</a> (Recurrent Network code tutorial, KR)</ul><p><strong><code class="language-plaintext highlighter-rouge">Next</code></strong> : 2021.07.03 9:00 PM KST</p><ul><li><strong>GRU part 2(Chloe, James)</strong></ul><blockquote><ul><li><a href=".">TBA</a></ul></blockquote><p>​</p><hr /></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/ml-dl/'>ML/DL</a>, <a href='/categories/deep-learning/'>Deep Learning</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/machine-learning/" class="post-tag no-text-decoration" >machine learning</a> <a href="/tags/deep-learning/" class="post-tag no-text-decoration" >deep learning</a> <a href="/tags/csc321/" class="post-tag no-text-decoration" >csc321</a> <a href="/tags/toronto/" class="post-tag no-text-decoration" >toronto</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=CSC321 스터디 진행 사항 (Toronto Univ. , Roger Grosse ) - INEED COFFEE&url=https://ineed-coffee.github.io/posts/CSC321-study-log/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=CSC321 스터디 진행 사항 (Toronto Univ. , Roger Grosse ) - INEED COFFEE&u=https://ineed-coffee.github.io/posts/CSC321-study-log/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=CSC321 스터디 진행 사항 (Toronto Univ. , Roger Grosse ) - INEED COFFEE&url=https://ineed-coffee.github.io/posts/CSC321-study-log/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/CSC321-study-log/">CSC321 스터디 진행 사항 (Toronto Univ. , Roger Grosse )</a><li><a href="/posts/CSC321-lec13.6/">【Lecture 13.6】Object Detection YOLO v1</a><li><a href="/posts/CSC321-lec13.5-part1/">【Lecture 13.5】Object Detection Faster R-CNN part1</a><li><a href="/posts/CSC321-sc.2/">【Special Course 2】Implementing Inception module using keras Functional API</a><li><a href="/posts/CSC321-sc.1/">【Special Course 1】DNN practice & keras overview from Colab</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/deep-learning/">deep learning</a> <a class="post-tag" href="/tags/csc321/">csc321</a> <a class="post-tag" href="/tags/cnn/">cnn</a> <a class="post-tag" href="/tags/colab/">colab</a> <a class="post-tag" href="/tags/object-detection/">object detection</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/sklearn/">sklearn</a> <a class="post-tag" href="/tags/git/">git</a> <a class="post-tag" href="/tags/github/">github</a> <a class="post-tag" href="/tags/machine-learning/">machine learning</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/CSC321-lec5/"><div class="card-body"> <span class="timeago small" > Jan 9 <i class="unloaded">2021-01-09T15:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>【Lecture 5】 Multilayer Perceptrons (CSC321 2017 winter)</h3><div class="text-muted small"><p> Course Study with CSC321 [2021.01.09] Topic : Lecture 5: Multilayer Perceptrons (Hayden) Notes : https://drive.google.com/file/d/1p446nFckVgzjhYFzZ7EABXLRX9Mq3QLN/view?usp=sharing (희원) L...</p></div></div></a></div><div class="card"> <a href="/posts/CSC321-lec6/"><div class="card-body"> <span class="timeago small" > Jan 14 <i class="unloaded">2021-01-14T15:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>【Lecture 6】 Backpropagation (CSC321 2017 winter)</h3><div class="text-muted small"><p> Course Study with CSC321 [2021.01.16] Topic : Lecture 6: Backpropagation (이동재) Notes : https://drive.google.com/file/d/1BydNGPxWEwRxiJobvu5dPq88xhRO2ypU/view?usp=sharing (동재) Links : ...</p></div></div></a></div><div class="card"> <a href="/posts/CSC321-lec7/"><div class="card-body"> <span class="timeago small" > Jan 30 <i class="unloaded">2021-01-30T15:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>【Lecture 7】 Optimization (CSC321 2017 winter)</h3><div class="text-muted small"><p> Course Study with CSC321 [2021.01.30] Topic : Lecture 7: Optimization Notes : https://drive.google.com/file/d/1gq4tCKfcwQ_QYRO8XYhdR3Y3UTfJQXNd/view?usp=sharing Links : Derivative of Logis...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/SVM/" class="btn btn-outline-primary" prompt="Older"><p>SVM 개념 정리 및 활용 (sklearn)</p></a> <a href="/posts/CSC321-lec5/" class="btn btn-outline-primary" prompt="Newer"><p>【Lecture 5】 Multilayer Perceptrons (CSC321 2017 winter)</p></a></div><script src="https://utteranc.es/client.js" repo="ineed-coffee/ineed-coffee.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2021 <a href="https://github.com/ineed-coffee">INEED COFFEE</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author."> Some rights reserved. </span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/deep-learning/">deep learning</a> <a class="post-tag" href="/tags/csc321/">csc321</a> <a class="post-tag" href="/tags/cnn/">cnn</a> <a class="post-tag" href="/tags/colab/">colab</a> <a class="post-tag" href="/tags/object-detection/">object detection</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/sklearn/">sklearn</a> <a class="post-tag" href="/tags/git/">git</a> <a class="post-tag" href="/tags/github/">github</a> <a class="post-tag" href="/tags/machine-learning/">machine learning</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://ineed-coffee.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
