<!DOCTYPE html><html lang="ko_KR" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="pv-cache-enabled" content="false"><meta name="generator" content="Jekyll v4.2.0" /><meta property="og:title" content="DecisionTree 개념 정리 및 활용 (sklearn)" /><meta name="author" content="INEED COFFEE" /><meta property="og:locale" content="ko_KR" /><meta name="description" content=":mag: Index" /><meta property="og:description" content=":mag: Index" /><link rel="canonical" href="https://ineed-coffee.github.io/posts/DecisionTree/" /><meta property="og:url" content="https://ineed-coffee.github.io/posts/DecisionTree/" /><meta property="og:site_name" content="INEED COFFEE" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-10-26T15:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="DecisionTree 개념 정리 및 활용 (sklearn)" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"datePublished":"2020-10-26T15:00:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://ineed-coffee.github.io/posts/DecisionTree/"},"description":":mag: Index","url":"https://ineed-coffee.github.io/posts/DecisionTree/","@type":"BlogPosting","author":{"@type":"Person","name":"INEED COFFEE"},"headline":"DecisionTree 개념 정리 및 활용 (sklearn)","dateModified":"2021-03-10T23:05:38+09:00","@context":"https://schema.org"}</script><title>DecisionTree 개념 정리 및 활용 (sklearn) | INEED COFFEE</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end">
<div class="profile-wrapper text-center">
<div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/favicons/character.jpg" alt="avatar" onerror="this.style.display='none'"> </a>
</div>
<div class="site-title mt-3"> <a href="/">INEED COFFEE</a>
</div>
<div class="site-subtitle font-italic">Much more !</div>
</div>
<ul class="w-100">
<li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a>
</li>
<li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a>
</li>
<li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a>
</li>
<li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a>
</li>
<li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a>
</li>
</ul>
<div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/ineed-coffee" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="javascript:location.href%20=%20'mailto:'%20+%20%5B'leey93ssu','gmail.com'%5D.join('@')" aria-label="email" class="order-4"> <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-5"> <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span>
</div>
</div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>DecisionTree 개념 정리 및 활용 (sklearn)</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div>
<i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel">Cancel</span>
</div></div><div id="main-wrapper">
<div id="main">
<div class="row">
<div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4">
<h1 data-toc-skip>DecisionTree 개념 정리 및 활용 (sklearn)</h1>
<div class="post-meta text-muted d-flex flex-column">
<div> <span class="semi-bold"> INEED COFFEE </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Mon, Oct 26, 2020, 3:00 PM +0900" prep="on"> Oct 26, 2020 <i class="unloaded">2020-10-26T15:00:00+09:00</i> </span>
</div>
<div> <span> <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Wed, Mar 10, 2021, 11:05 PM +0900" prefix="Updated "> Mar 10 <i class="unloaded">2021-03-10T23:05:38+09:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3789 words">21 min</span>
</div>
</div>
<div class="post-content">
<h1 id="mag-index">
<img class="emoji" title=":mag:" alt=":mag:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f50d.png" height="20" width="20"> Index</h1>
<ul>
<li><a href="#idx1">의사결정나무(Decision Tree)는 뭘까?</a></li>
<li><a href="#idx2">의사결정나무의 철학: Information Gain</a></li>
<li><a href="#idx3">의사결정나무의 종류 : Type of Tree</a></li>
<li><a href="#idx4">의사결정나무의 학습과정: Learning Process</a></li>
<li><a href="#idx5">sklearn 라이브러리를 활용한 의사 결정나무</a></li>
<li><a href="#idx6">참고자료</a></li>
</ul>
<hr>
<h3 id="radio_button-의사결정나무decision-tree는-뭘까--">
<img class="emoji" title=":radio_button:" alt=":radio_button:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f518.png" height="20" width="20"> 의사결정나무(Decision Tree)는 뭘까? <a id="idx1"></a>
</h3>
<p>의사결정나무란 데이터 사이 존재하는 <strong>패턴</strong> 을 찾아 이 규칙들의 <strong>조합</strong> 으로 예측 모델을 만드는데 쓰이는 알고리즘으로 기계학습의 기초가 되는 알고리즘 중 하나이다.</p>
<p>그림으로 그렸을때 트리의 형태를 이루기 때문에 ‘나무’ 라는 말이 붙었는데 이는 추후 여러 의사결정나무를 앙상블 기법을 통해 활용한 <strong>Random Forest</strong> 알고리즘에도 영향을 주었다.</p>
<p>의사결정나무는 설명변수를 <strong>*하나씩만*</strong> 활용하여 가지뻗기를 진행하는데 이는 우리가 어릴적 한번씩 해봤던 ‘스무고개’ 놀이를 통해 이해할 수 있다.</p>
<blockquote><p>의사결정나무에 대한 설명을 보면 <code class="language-plaintext highlighter-rouge">설명변수</code>라는 용어가 쓰이는데 <code class="language-plaintext highlighter-rouge">입력특성</code>,<code class="language-plaintext highlighter-rouge">독립변수</code> 정도로 이해하면 된다.</p></blockquote>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://t1.daumcdn.net/thumb/R720x0/?fname=http://t1.daumcdn.net/brunch/service/user/1oU7/image/OG5rMwYpRcG4gRPFv8qgLslNLTQ.png" alt="스무고개 그림"></p>
<p><a href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fbrunch.co.kr%2F%40kakao-it%2F157&amp;psig=AOvVaw1D35xHZ-Geohyk-iCIprD-&amp;ust=1601041536507000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCIDxttT2gewCFQAAAAAdAAAAABAX">이미지 출처</a></p>
<p>다음과 같은 스무고개 놀이를 했을 때 <strong><code class="language-plaintext highlighter-rouge">다리</code></strong> ,<strong><code class="language-plaintext highlighter-rouge">고양이와 크기가 비슷</code></strong> , <strong><code class="language-plaintext highlighter-rouge">바다에 사는</code></strong> 은 모두 위에서 언급한 설명변수에 해당한다. 데이터에 대한 패턴을 찾아 트리 구조로 규칙을 조합해놓은 모양이다. 한번에 설명변수 하나씩만을 이용해 가지를 뻗게되어 <strong>terminal node</strong> , <strong>leaf node</strong> 라고 부르는 트리의 최하위 항목들을 살펴보면 초기 데이터의 상호 베타적인 집합으로 분류되어 있는것을 확인할 수 있다.</p>
<p>의사결정나무는 이런 모양으로 규칙을 조합하여 데이터에 대한 예측 모델을 이룬다. 이는 <code class="language-plaintext highlighter-rouge">분류(Classification)</code> 문제와 <code class="language-plaintext highlighter-rouge">회귀(Regression)</code> 문제 모두 적용가능한데 , 분류 문제의 경우 해당 데이터가 최종적으로 속한 최하위 그룹의 최빈값을 예측값으로 활용하고 회귀 문제의 경우 그 그룹내 데이터의 평균값을 예측값으로 활용한다.즉, N개의 최하위 노드를 갖는 의사결정나무로부터 얻을 수 있는 예측값의 종류는 <code class="language-plaintext highlighter-rouge">분류|회귀 문제와 상관없이 동일하게 최대 N개이다.</code></p>
<hr>
<h3 id="radio_button-의사결정-나무의-철학-information-gain-">
<img class="emoji" title=":radio_button:" alt=":radio_button:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f518.png" height="20" width="20"> 의사결정 나무의 철학: Information Gain <a id="idx2"></a>
</h3>
<p>앞에서 언급한 스무고개 놀이를 하는데 만약 첫 질문에 <strong>‘혹시 매운 음식인가요?’</strong> 라고 물었는데 <strong>‘네’</strong> 라는 결과가 나온다면 우리는 <strong>‘나이스!’</strong> 를 외칠것이다. 왜일까?</p>
<p>이는 우리가 고려해야하는 정답 후보 데이터가 아주 세부적으로 바뀌었기 때문이다. 의사결정나무에서는 이를 <strong><code class="language-plaintext highlighter-rouge">정보획득(Information Gain)</code></strong> 이라 부른다. 정확한 의미는 의사결정나무에서 분기가 일어날때 데이터의 순도 변화량을 정보획득이라 부른다. 데이터의 <strong>순도(homogeneity)</strong> 란 말 그대로 데이터가 얼마나 단조로운/변화가 많은 혹은 종류가 적은/많은가 정도로 이해하면 되는데 이와 반대되는 개념으로 <strong>불순도(impurity)</strong> 를 통해 정보획득을 분기 전후의 불순도 감소정도로 설명하기도 한다.</p>
<blockquote><p>방금 정보획득을 순도의 증가량 , 불순도의 감소량 이라는 표현을 통해 설명하였는데 그러면 이는 수치적으로 어떻게 표현될까?</p></blockquote>
<p>순도,불순도를 수치로 나타내기 위한 종류는 대표적으로 3가지가 있다. 바로 <code class="language-plaintext highlighter-rouge">Entropy</code> , <code class="language-plaintext highlighter-rouge">Gini Index</code> , <code class="language-plaintext highlighter-rouge">Misclassification Error</code> 인데, 이 중 <code class="language-plaintext highlighter-rouge">Entropy</code> 지표에 대해 알아보자면 다음과 같은 식으로 정의된다.</p>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/inital_entropy.PNG" alt="초기 엔트로피"></p>
<p>초기 m 개의 분류를 가진 데이터에 대해서는 위의 식 처럼 각 분류의 확률과 확률의 로그값을 모두 더한 값이 초기 엔트로피 값이다. 이 상태에서 데이터나 나뉘게 되면 다음과 같은 방식으로 엔트로피를 구하게 된다.</p>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/general_entropy.PNG" alt="일반 엔트로피"></p>
<p>각 나뉜 각 그룹에 대해 엔트로피를 구한 다음 그룹의 상대 부피인 R 값을 곱하여 다시 더하는 식이다.</p>
<p>의사결정나무의 학습방법에서 핵심은 저 엔트로피 지수가 낮아지는 쪽으로 분기를 하는것이다.</p>
<hr>
<h3 id="radio_button-의사결정나무의-종류--type-of-tree-">
<img class="emoji" title=":radio_button:" alt=":radio_button:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f518.png" height="20" width="20"> 의사결정나무의 종류 : Type of Tree <a id="idx3"></a>
</h3>
<p>위에서 언급한 3가지 대표 지표 외에도 불순도를 측정하는 다양한 척도와 계산 법이 존재하는데 이는 종속변수의 성격이 연속형인지 범주형인지에 따라 나뉘며 이에 따라 다양한 형태의 의사결정나무가 존재한다. 아래는 각 형태의 간략한 설명이다. 가장 많이 쓰이고 있는 모델은 CART 모델이다.</p>
<div class="table-wrapper"><table>
<thead><tr>
<th style="text-align: center"> </th>
<th style="text-align: center">범주형 종속변수</th>
<th style="text-align: center">연속형 종속변수</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align: center">CHAID</td>
<td style="text-align: center">카이제곱 통계량</td>
<td style="text-align: center">ANOVA F-통계량</td>
</tr>
<tr>
<td style="text-align: center">CART</td>
<td style="text-align: center">지니지수</td>
<td style="text-align: center">분산감소량</td>
</tr>
<tr>
<td style="text-align: center">C4.5</td>
<td style="text-align: center">엔트로피지수</td>
<td style="text-align: center"> </td>
</tr>
</tbody>
</table></div>
<ol>
<li>
<strong>CART (Classification and Regression Tree)</strong><ul><li>가장 널리 쓰이는 의사결정나무 알고리즘. 범주형 종속변수에 대해서는 지니지수를 기준으로 분기가 일어나고 연속형 종속변수에 대해서는 분산을 활용한 이진분리가 기준이 된다. <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20">
</li></ul>
</li>
<li>
<strong>C4.5</strong><ul><li>각 노드에서 다중분리(multiple split)가 가능하다는 것이 특징이다. 범주형 종속변수의 학습에만 활용되는 알고리즘으로 엔트로피 지수를 통해 분기가 일어난다.</li></ul>
</li>
<li>
<strong>CHAID (CHi-sqaured Automatic Interaction Detection)</strong><ul><li>다른 알고리즘과 달리 <code class="language-plaintext highlighter-rouge">*Full Tree</code> 를 만족할 때까지 분기가 일어나지 않고 적당한 크기에서 분기를 중단하는것이 특징이다. 분기 기준으로는 카이제곱 통계량을 활용하고 독립변수는 범주형 데이터여야 한다는 특징 또한 가지고 있다.</li></ul>
</li>
</ol>
<p><code class="language-plaintext highlighter-rouge">*Full Tree</code> : 모든 leaf_node 의 순도가 100% 인 나무 모델을 말한다.</p>
<hr>
<h3 id="radio_button-의사결정나무의-학습과정---learning-process">
<img class="emoji" title=":radio_button:" alt=":radio_button:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f518.png" height="20" width="20"> 의사결정나무의 학습과정 : Learning Process<a id="idx4"></a>
</h3>
<p>의사결정나무의 학습과정은 신경망 모델의 1회 학습과정과 시각적으로 유사하다. 2 단계를 거쳐 모델이 생성되는데 바로 <strong><code class="language-plaintext highlighter-rouge">재귀적 분기(recursive partitioning)</code></strong> 와 <strong><code class="language-plaintext highlighter-rouge">가지치기(pruning)</code></strong> 이다.</p>
<p>계산과정과 함께 이해하기 위해 다음과 같은 샘플 데이터를 생각해보자.</p>
<div class="table-wrapper"><table>
<thead><tr>
<th>A(독립)</th>
<th>B(독립)</th>
<th>C(종속)</th>
</tr></thead>
<tbody>
<tr>
<td>16.6</td>
<td>2</td>
<td>YES</td>
</tr>
<tr>
<td>5.4</td>
<td>3</td>
<td>NO</td>
</tr>
<tr>
<td>20</td>
<td>3</td>
<td>YES</td>
</tr>
<tr>
<td>43.6</td>
<td>3</td>
<td>YES</td>
</tr>
<tr>
<td>5</td>
<td>2</td>
<td>NO</td>
</tr>
<tr>
<td>12</td>
<td>3</td>
<td>YES</td>
</tr>
<tr>
<td>12.7</td>
<td>2</td>
<td>NO</td>
</tr>
<tr>
<td>17.5</td>
<td>2</td>
<td>NO</td>
</tr>
</tbody>
</table></div>
<p>A,B 의 독립 변수에 의해 C의 종속변수 값이 정해지는 데이터일때,</p>
<p><strong>1. 재귀적 분기 (Recursive Partitioning)</strong></p>
<p>먼저 해당 데이터에 대해 분기가 일어난다.</p>
<p>초기 엔트로피 값은</p>
<p><code class="language-plaintext highlighter-rouge">YES</code> : -(4/8) * (log(4/8)) = 0.5</p>
<p><code class="language-plaintext highlighter-rouge">NO</code> : -(4/8) * (log(4/8)) = 0.5</p>
<p>로 0.5 + 0.5 = 1 이다. (엔트로피 지수에서 최대 값이 1이다. 즉 가장 불순도가 높은 유형이 범주 수만큼 나뉘어 있는 데이터)</p>
<p>이때 , 독립 변수 하나를 고정하여 그 값으로 정렬을 한다. (A 기준이라면)</p>
<div class="table-wrapper"><table>
<thead><tr>
<th>A(독립)</th>
<th>B(독립)</th>
<th>C(종속)</th>
</tr></thead>
<tbody>
<tr>
<td>5</td>
<td>2</td>
<td>NO</td>
</tr>
<tr>
<td>5.4</td>
<td>3</td>
<td>NO</td>
</tr>
<tr>
<td>12</td>
<td>3</td>
<td>YES</td>
</tr>
<tr>
<td>12.7</td>
<td>2</td>
<td>NO</td>
</tr>
<tr>
<td>16.6</td>
<td>2</td>
<td>YES</td>
</tr>
<tr>
<td>17.5</td>
<td>2</td>
<td>NO</td>
</tr>
<tr>
<td>20</td>
<td>3</td>
<td>YES</td>
</tr>
<tr>
<td>43.6</td>
<td>3</td>
<td>YES</td>
</tr>
</tbody>
</table></div>
<p>정렬이 끝나면 총 8개의 데이터가 위에서부터 1:7 , 2:6 , 3:5 , … 의 비율로 분기될때 엔트로피를 계산하여 정보획득을 계산한다.</p>
<p><code class="language-plaintext highlighter-rouge">ex) 1:7</code></p>
<p><code class="language-plaintext highlighter-rouge">1</code> : 1/8(데이터 비율) * {-1*log(1)} = 0 (데이터가 한 범주에 대해서만 존재하므로)</p>
<div class="table-wrapper"><table>
<thead><tr>
<th>A(독립)</th>
<th>B(독립)</th>
<th>C(종속)</th>
</tr></thead>
<tbody><tr>
<td>5</td>
<td>2</td>
<td>NO</td>
</tr></tbody>
</table></div>
<p><code class="language-plaintext highlighter-rouge">2</code> : 7/8(데이터 비율) * {-4/7 * log(4/7) + -3/7 * log(3/7)} (각각 YES , NO 데이터 항목) ≒ 0.5649</p>
<div class="table-wrapper"><table>
<thead><tr>
<th>A(독립)</th>
<th>B(독립)</th>
<th>C(종속)</th>
</tr></thead>
<tbody>
<tr>
<td>5.4</td>
<td>3</td>
<td>NO</td>
</tr>
<tr>
<td>12</td>
<td>3</td>
<td>YES</td>
</tr>
<tr>
<td>12.7</td>
<td>2</td>
<td>NO</td>
</tr>
<tr>
<td>16.6</td>
<td>2</td>
<td>YES</td>
</tr>
<tr>
<td>17.5</td>
<td>2</td>
<td>NO</td>
</tr>
<tr>
<td>20</td>
<td>3</td>
<td>YES</td>
</tr>
<tr>
<td>43.6</td>
<td>3</td>
<td>YES</td>
</tr>
</tbody>
</table></div>
<p><code class="language-plaintext highlighter-rouge">분기 후 엔트로피</code> = 0 + 0.5649 = 0.5649</p>
<p>∴ <code class="language-plaintext highlighter-rouge">정보 획득</code> = 1 - 0.5649 = 0.4251</p>
<p>위와 같은 작업을 <strong><code class="language-plaintext highlighter-rouge">모든 독립변수</code></strong> 에 대해서 <strong><code class="language-plaintext highlighter-rouge">모든 비율</code></strong> 로 분기될때를 계산하여 가장 정보획득이 가장 큰 조건을 택해 분기하는 것이다.</p>
<blockquote><p>wow ! 난 여기서 가장 와닿았다.</p></blockquote>
<p>그럼 그 다음 분기는 어떻게 일어날까?</p>
<p>예를 들어 위 데이터가 A 변수를 위에서부터 3:5 로 분할하여 분기할때 가장 정보획득이 커 Left 그룹과 Right 그룹으로 나누었다고 하자. 그럼 이후에는 Left 그룹의 3개 데이터로 모든 최하위 그룹이 순수 노드가 될때까지 즉, ‘YES’ 혹은 ‘NO’ 의 데이터만 가지고 있는 그룹이 될 때까지 Left - Left , Left - Right , … 나누고 작업이 끝나면 처음 나누었던 Right 그룹에 대해 같은 방식으로 분기가 일어난다. 이 때문에 분기 과정 앞에 <strong><code class="language-plaintext highlighter-rouge">재귀적</code></strong> 이라는 말이 붙는다.</p>
<p><strong>2. 가지치기 (pruning)</strong></p>
<p>분기 작업이 모두 끝나면 이후에는 가지치기 작업이 일어난다. 가지치는 직관적의미 그대로 수 많은 가지로 분기하여 여러 leaf 노드를 가지고 있는 나무의 상위 노드에서 가지를 쳐내며 일부 데이터를 병합하는 과정이다.</p>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://alanjeffares.files.wordpress.com/2018/07/pruning-001.png?w=601&amp;h=334" alt="가지치기"></p>
<p><a href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Falanjeffares.wordpress.com%2Ftutorials%2Fdecision-tree%2F&amp;psig=AOvVaw0DujziE98KAzAU4_qLs720&amp;ust=1601217782278000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCKi6uJ2Hh-wCFQAAAAAdAAAAABAK">이미지 출처</a></p>
<blockquote><p>순수 노드인 최하위 데이터들을 병합하여 상위 노드를 최하위 노드로 만들면 더이상 순수 노드가 아닐텐데 왜 이와 같은 작업을 하는것일까?</p></blockquote>
<p>이유는 바로 <strong>과적합( Over-Fitting)</strong> 을 방지하기 위해서이다. 과대적합에 대한 내용은 또 별도로 정리할 예정이니 간단하게 설명하자면,</p>
<p>모델에서 과적합이 발생했다는 의미는 학습 데이터에 너무도 정교하고 세세하게 학습을 완료해서 학습에 쓰였던 데이터를 입력으로 받게 되면 높은 정확도/예측률 을 가지지만 비슷한 새 데이터에 대해서는 참담한 성능을 보이는 <strong><code class="language-plaintext highlighter-rouge">일반화 성능</code></strong> 이 꽝이 되었다는 의미이다.</p>
<p>가지치기의 과정도 분기 과정과 비슷하게 그 기준인 <strong><code class="language-plaintext highlighter-rouge">비용함수 (Cost Fucntion)</code></strong> 의 정도를 모든 분기점에 대해 조사한 후 손실이 가장 적은 분기점을 병합하는 식인데 <code class="language-plaintext highlighter-rouge">TOP-Down</code> 방식과 <code class="language-plaintext highlighter-rouge">BOTTOM-Up</code> 방식이 있다.</p>
<p><strong>※ 참고 비용함수 (Cost Function) 의 표현 식</strong></p>
<p>의사결정나무 모델 DT 에 대해</p>
<p><strong><code class="language-plaintext highlighter-rouge">CC(DT) = E(DT) + α X L(DT)</code></strong></p>
<ul>
<li>CC : Cost Complexity , 최종 비용</li>
<li>E : Error , 해당 분기를 가지치기 하였을 때 , 트레이닝/학습 misclassification error</li>
<li>α : 정규화 상수 ( 사용자에 의해 0.1~0.01 정도의 값으로 설정됨)</li>
<li>L : Leaves , 모델의 최하위 노드의 수</li>
</ul>
<hr>
<h3 id="radio_button-sklearn-라이브러리를-활용한-의사-결정나무">
<img class="emoji" title=":radio_button:" alt=":radio_button:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f518.png" height="20" width="20"> sklearn 라이브러리를 활용한 의사 결정나무<a id="idx5"></a>
</h3>
<p><img class="emoji" title=":pencil2:" alt=":pencil2:" src="https://github.githubassets.com/images/icons/emoji/unicode/270f.png" height="20" width="20"> <strong>의사 결정나무 객체 생성</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td>
<td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">slkearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>

<span class="n">DT_C</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="n">DT_R</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">()</span>
</pre></td>
</tr></tbody></table></code></div></div>
<blockquote><p><strong>세부 옵션</strong> :</p></blockquote>
<ul>
<li>
<code class="language-plaintext highlighter-rouge">criterion</code> : 분기의 기준에서 쓰일 지표를 설정.<ul>
<li>Classifier : ‘gini’ (지니 계수 , ‘entropy’ (엔트로피 지수)</li>
<li>Regressor : ‘mse’ (mean-squared-error) , ‘mae’ (mean-absolute-error)</li>
</ul>
</li>
<li>
<code class="language-plaintext highlighter-rouge">max_features</code> : 트리 구성에 쓰일 설명변수의 수를 설정 (int, float, None, Auto)</li>
<li>
<code class="language-plaintext highlighter-rouge">max_depth</code> : 트리의 최대 깊이를 설정.</li>
<li>
<code class="language-plaintext highlighter-rouge">min_samples_split</code> : min_samples_leaf 와 혼동 주의. 현재 노드가 분기를 하기에 최소로 만족해야하는 샘플 수를 설정. 이 파라미터 값 이하의 수를 가진 노드는 분기 고려대상 바로 제외</li>
<li>
<code class="language-plaintext highlighter-rouge">min_samples_leaf</code> : 분기가 일어날 때 하위 노드에 각각 최소로 포함되어야 하는 데이터 수를 설정. 만약 2라면 왼쪽 노드에도 최소 2개, 오른쪽 노드에도 최소 2개의 데이터가 포함되는 조건으로 분기가 일어나야함.</li>
<li>
<code class="language-plaintext highlighter-rouge">random_state</code> : 트리의 구성에서 무작위한 고려가 필요시 이용되는 파라미터. 예를 들어 max_feature 를 설정해 놓아서 각 분기마다 어떤 설명변수를 골라 criterion을 조사할지 , criterion을 조사했는데 완전히 동일한 둘 이상의 설명변수가 존재할 때 어느 설명변수를 기준으로 분할할지 등.</li>
</ul>
<p><img class="emoji" title=":pencil2:" alt=":pencil2:" src="https://github.githubassets.com/images/icons/emoji/unicode/270f.png" height="20" width="20"> <strong>의사 결정나무 객체 학습</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td>
<td class="rouge-code"><pre><span class="n">model_c</span> <span class="o">=</span> <span class="n">DT_C</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span><span class="n">ydata</span><span class="p">,</span><span class="n">sample_weight</span><span class="p">)</span>
<span class="n">model_r</span> <span class="o">=</span> <span class="n">DT_R</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span><span class="n">ydata</span><span class="p">,</span><span class="n">sample_weight</span><span class="p">)</span>
</pre></td>
</tr></tbody></table></code></div></div>
<blockquote><p>파라미터 세부내용</p></blockquote>
<ul>
<li>xdata : 학습데이터의 입력값</li>
<li>ydata : 학습데이터의 출력값</li>
<li>sample_weight : optional 파라미터로 각 설명변수의 가중치 배열을 전달 가능. 분기 조사 과정에서 적용된다.</li>
</ul>
<p><img class="emoji" title=":pencil2:" alt=":pencil2:" src="https://github.githubassets.com/images/icons/emoji/unicode/270f.png" height="20" width="20"> <strong>의사 결정나무 객체 예측/분류</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td>
<td class="rouge-code"><pre><span class="n">predict_C</span> <span class="o">=</span> <span class="n">model_C</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xtest</span><span class="p">)</span>
<span class="n">predict_R</span> <span class="o">=</span> <span class="n">model_r</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xtest</span><span class="p">)</span>
</pre></td>
</tr></tbody></table></code></div></div>
<blockquote><p>참고</p></blockquote>
<p>예측 분류/값 에 대해 <strong>배열</strong> 형태로 반환받는다.</p>
<p><img class="emoji" title=":pencil2:" alt=":pencil2:" src="https://github.githubassets.com/images/icons/emoji/unicode/270f.png" height="20" width="20"> <strong>의사 결정나무 객체 평가</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td>
<td class="rouge-code"><pre><span class="n">score_c</span> <span class="o">=</span> <span class="n">model_c</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">xtest</span><span class="p">,</span><span class="n">ytest</span><span class="p">,</span><span class="n">sample_weight</span><span class="p">)</span>
<span class="n">score_r</span> <span class="o">=</span> <span class="n">model_r</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">xtest</span><span class="p">,</span><span class="n">ytest</span><span class="p">,</span><span class="n">sample_weight</span><span class="p">)</span>
</pre></td>
</tr></tbody></table></code></div></div>
<blockquote><p>각 문제별 평가기준</p></blockquote>
<ul><li>
<code class="language-plaintext highlighter-rouge">분류(classification)</code><ul>
<li>단일 레이블의 경우 ACC (정확도) 를 기준으로 0~1 사이 값으로 평가</li>
<li>다중 레이블의 경우 각 레이블의 ACC 값의 평균으로 평가한다.</li>
</ul>
</li></ul>
<p>※ 다중 레이블은 ydata 의 컬럼이 2 이상인 데이터이다.</p>
<ul><li>
<code class="language-plaintext highlighter-rouge">회귀(Regression)</code><ul><li>
<strong>R2</strong> 라고 많이 표현하는 결정계수를 평가 지표를 활용한다. 모든 데이터를 평균치로 예측하는 단순 모델(Zero-R)과 비교하였을 때 얼마나 개선된 성능을 보이는지를 구하는 결정계수의 값 또한 ACC 와 마찬가지로 0~1 사이의 값을 가진다.</li></ul>
</li></ul>
<p><img class="emoji" title=":pencil2:" alt=":pencil2:" src="https://github.githubassets.com/images/icons/emoji/unicode/270f.png" height="20" width="20"> <strong>의사 결정나무 기타 기능</strong></p>
<ul><li>
<img class="emoji" title=":bulb:" alt=":bulb:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4a1.png" height="20" width="20"> <strong>sklearn.tree 서브패키지의 plot_tree</strong>
</li></ul>
<p>의사결정나무 객체를 전달하면 현재 학습이 완료된 객체의 모습을 시각화하여 볼 수 있다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td>
<td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">plot_tree</span> <span class="k">as</span> <span class="n">pt</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">fig</span> <span class="p">,</span> <span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">)</span>
<span class="n">tree_picture</span> <span class="o">=</span> <span class="n">pt</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">)</span>
</pre></td>
</tr></tbody></table></code></div></div>
<p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/DT_visualize.jpg" alt="트리 그림"></p>
<hr>
<h3 id="radio_button-참고-자료-">
<img class="emoji" title=":radio_button:" alt=":radio_button:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f518.png" height="20" width="20"> 참고 자료 <a id="idx6"></a>
</h3>
<ul>
<li><a href="https://ratsgo.github.io/machine%20learning/2017/03/26/tree/">의사결정나무(Decision Tree) by ratsgo</a></li>
<li><a href="https://freedata.tistory.com/38">의사결정나무 by chocoma</a></li>
</ul>
</div>
<div class="post-tail-wrapper text-muted">
<div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href="/categories/ml-dl/">ML/DL</a>, <a href="/categories/machine-learning/">Machine Learning</a>
</div>
<div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/decision-tree/" class="post-tag no-text-decoration">decision tree</a> <a href="/tags/sklearn/" class="post-tag no-text-decoration">sklearn</a> <a href="/tags/r/" class="post-tag no-text-decoration">r</a> <a href="/tags/python/" class="post-tag no-text-decoration">python</a>
</div>
<div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
<div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div>
<div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=DecisionTree%20%EA%B0%9C%EB%85%90%20%EC%A0%95%EB%A6%AC%20%EB%B0%8F%20%ED%99%9C%EC%9A%A9%20(sklearn)%20-%20INEED%20COFFEE&amp;url=https://ineed-coffee.github.io/posts/DecisionTree/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=DecisionTree%20%EA%B0%9C%EB%85%90%20%EC%A0%95%EB%A6%AC%20%EB%B0%8F%20%ED%99%9C%EC%9A%A9%20(sklearn)%20-%20INEED%20COFFEE&amp;u=https://ineed-coffee.github.io/posts/DecisionTree/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=DecisionTree%20%EA%B0%9C%EB%85%90%20%EC%A0%95%EB%A6%AC%20%EB%B0%8F%20%ED%99%9C%EC%9A%A9%20(sklearn)%20-%20INEED%20COFFEE&amp;url=https://ineed-coffee.github.io/posts/DecisionTree/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span>
</div>
</div>
</div>
</div></div>
<div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down">
<div class="access">
<div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2">
<li><a href="/posts/CSC321-study-log/">CSC321 스터디 진행 사항 (Toronto Univ. , Roger Grosse )</a></li>
<li><a href="/posts/CSC321-lec13.6/">【Lecture 13.6】Object Detection YOLO v1</a></li>
<li><a href="/posts/CSC321-lec13.5-part1/">【Lecture 13.5】Object Detection Faster R-CNN part1</a></li>
<li><a href="/posts/CSC321-sc.2/">【Special Course 2】Implementing Inception module using keras Functional API</a></li>
<li><a href="/posts/CSC321-sc.1/">【Special Course 1】DNN practice &amp; keras overview from Colab</a></li>
</ul>
</div>
<div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/deep-learning/">deep learning</a> <a class="post-tag" href="/tags/csc321/">csc321</a> <a class="post-tag" href="/tags/cnn/">cnn</a> <a class="post-tag" href="/tags/colab/">colab</a> <a class="post-tag" href="/tags/object-detection/">object detection</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/sklearn/">sklearn</a> <a class="post-tag" href="/tags/git/">git</a> <a class="post-tag" href="/tags/github/">github</a> <a class="post-tag" href="/tags/machine-learning/">machine learning</a>
</div>
</div>
</div>
<script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav>
</div>
</div>
</div>
<div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4">
<div id="related-posts" class="mt-5 mb-2 mb-sm-4">
<h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3>
<div class="card-deck mb-4">
<div class="card"> <a href="/posts/Naive-Bayesian/"><div class="card-body"> <span class="timeago small"> Oct 28, 2020 <i class="unloaded">2020-10-28T15:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Naive Bayesian 개념 정리 및 활용 (sklearn &amp; R)</h3>
<div class="text-muted small"><p> <img class="emoji" title=":mag:" alt=":mag:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f50d.png" height="20" width="20"> Index 나이브 베이즈(Naive Bayes) 알고리즘이란? 조건부 확률에서 베이즈 공식까지 나이브 베이즈 알고리즘을 머신러닝에 어떻게 적용하는걸까? 나이브 베이즈 모델의 종류 나이브 베이즈 알고리즘의 장단점 R을 활용한 나이브 베이즈...</p></div>
</div></a>
</div>
<div class="card"> <a href="/posts/RandomForest/"><div class="card-body"> <span class="timeago small"> Oct 26, 2020 <i class="unloaded">2020-10-26T15:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>RandomForest 개념 정리 및 활용 (sklearn)</h3>
<div class="text-muted small"><p> <img class="emoji" title=":mag:" alt=":mag:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f50d.png" height="20" width="20"> Index 랜덤 포레스트(Random Forest)는 무엇일까? 랜덤 포레스트의 핵심 : bagging (bootstrap + aggregate) 랜덤 포레스트의 중요 매개변수 sklearn 라이브러리를 활용한 랜덤 포레스트 Reference <img class="emoji" title=":radio_button:" alt=":radio_button:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f518.png" height="20" width="20"> 랜덤 포레스트(Random Forest)는 ...</p></div>
</div></a>
</div>
<div class="card"> <a href="/posts/KNN/"><div class="card-body"> <span class="timeago small"> Oct 27, 2020 <i class="unloaded">2020-10-27T15:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>KNN 개념 정리 및 활용 (sklearn)</h3>
<div class="text-muted small"><p> <img class="emoji" title=":mag:" alt=":mag:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f50d.png" height="20" width="20"> Index k-최근접 이웃 알고리즘 이란? (KNN) k-최근접 이웃 알고리즘의 동작 원리 k-최근접 이웃 알고리즘의 장단점 sklearn 패키지를 활용한 KNN 참고자료 <img class="emoji" title=":radio_button:" alt=":radio_button:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f518.png" height="20" width="20"> k-최근접 이웃 알고리즘 이란? (KNN) ...</p></div>
</div></a>
</div>
</div>
</div>
<div class="post-navigation d-flex justify-content-between"> <a href="/posts/Types-of-data-and-how-to-analyze/" class="btn btn-outline-primary" prompt="Older"><p>Types of data and how to analyze</p></a> <a href="/posts/Parametric-VS.-Non-Parametric-method/" class="btn btn-outline-primary" prompt="Newer"><p>Parametric Vs. Non-parametric (모수적 Vs. 비모수적)</p></a>
</div>
<script src="https://utteranc.es/client.js" repo="ineed-coffee/ineed-coffee.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script>
</div></div></div>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('.post-content img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center">
<div class="footer-left"><p class="mb-0"> © 2021 <a href="https://github.com/ineed-coffee">INEED COFFEE</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author."> Some rights reserved. </span></p></div>
<div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div>
</div></footer>
</div>
<div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content">
<div id="search-hints">
<h4 class="text-muted mb-4">Trending Tags</h4>
<a class="post-tag" href="/tags/deep-learning/">deep learning</a> <a class="post-tag" href="/tags/csc321/">csc321</a> <a class="post-tag" href="/tags/cnn/">cnn</a> <a class="post-tag" href="/tags/colab/">colab</a> <a class="post-tag" href="/tags/object-detection/">object detection</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/sklearn/">sklearn</a> <a class="post-tag" href="/tags/git/">git</a> <a class="post-tag" href="/tags/github/">github</a> <a class="post-tag" href="/tags/machine-learning/">machine learning</a>
</div>
<div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
</div></div>
</div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://ineed-coffee.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
